{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4275851-2816-4903-91c3-8b4a4c489b12",
   "metadata": {},
   "source": [
    "# Project Overview: Predicting Loan Defaults\n",
    "\n",
    "**Executive Summary**  \n",
    "This project aims to develop a machine learning model to predict whether the customers of a financial institution will default on a loan based on data from their loan application. By accurately identifying potential defaulters, financial institutions can make more informed lending decisions, reduce losses, improve profitability, and increase operational efficiency through the automation of risk assessment.\n",
    "\n",
    "**Problem**  \n",
    "Predicting loan defaults is a challenging task due to the multitude of influencing factors such as customers' demographic, financial, location, and behavioral attributes. Traditional default prediction models often oversimplify complex relationships between customer features and default risk. Machine learning offers enhanced predictive capability by capturing non-linear patterns and intricate dependencies in loan application data, enabling more accurate predictions of loan default risk.\n",
    "\n",
    "**Objectives**  \n",
    "The project aims to:\n",
    "- Develop a machine learning model to predict loan defaults using customer data from loan applications.\n",
    "- Compare multiple models (e.g., Logistic Regression, Random Forest, XGBoost) using a suitable evaluation metric (such as AUC-PR).\n",
    "- Identify key factors influencing loan default risk through feature importance analysis.\n",
    "\n",
    "**Value Proposition**  \n",
    "This project enables financial institutions to reduce loan default rates and make better and faster lending decisions by leveraging machine learning for automated and improved risk assessment. \n",
    "\n",
    "**Business Goals**  \n",
    "The project aims to achieve the following business goals:\n",
    "- Reduce losses by 5M-10M INR within 12 months of model deployment by decreasing the loan default rate by 10%-20%.\n",
    "- Decrease loan processing time by 25%-40% by automating risk assessment, leading to less time spent on manual evaluations.\n",
    "- Ensure 100% compliance with regulatory requirements and fair lending practices.\n",
    "\n",
    "**Data**  \n",
    "The dataset contains information provided by customers of a financial institution during the loan application process. It is sourced from the \"Loan Prediction Based on Customer Behavior\" dataset by Subham Jain, available on [Kaggle](https://www.kaggle.com/datasets/subhamjain/loan-prediction-based-on-customer-behavior). \n",
    "\n",
    "Dataset Statistics:\n",
    "- Training set size: 252,000 records (12.3% defaults)\n",
    "- Test set size: 28,000 records (12.8% defaults)\n",
    "- 11 Features:\n",
    "  - Demographic: Age, married, profession\n",
    "  - Financial: Income, house ownership, car ownership\n",
    "  - Location: City, state\n",
    "  - Behavioral: Experience, current job years, current house years\n",
    "\n",
    "Data Overview Table:\n",
    "\n",
    "| Column | Description | Storage Type | Semantic Type | Theoretical Range | Training Data Range |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| Risk Flag | Defaulted on loan (0: No, 1: Yes) | Integer | Categorical (Binary) | [0, 1] | [0, 1] |\n",
    "| Income | Income of the applicant | Integer | Numerical | [0, ∞] | [10K, 10M] |\n",
    "| Age | Age of the applicant (in years) | Integer | Numerical | [18, ∞] | [21, 79] |\n",
    "| Experience | Work experience (in years) | Integer | Numerical | [0, ∞] | [0, 20] |\n",
    "| Profession | Applicant's profession | String | Categorical (Nominal) | Any profession [e.g., \"Architect\", \"Dentist\"] | 51 unique professions |\n",
    "| Married | Marital status | String | Categorical (Binary) | [\"single\", \"married\"] | [\"single\", \"married\"] |\n",
    "| House Ownership | Applicant owns or rents a house | String | Categorical (Nominal) | [\"rented\", \"owned\", \"norent_noown\"] | [\"rented\", \"owned\", \"norent_noown\"] |\n",
    "| Car Ownership | Whether applicant owns a car | String | Categorical (Binary) | [\"yes\", \"no\"] | [\"yes\", \"no\"] |\n",
    "| Current Job Years | Years in the current job | Integer | Numerical | [0, ∞] | [0, 14] |\n",
    "| Current House Years | Years in the current house | Integer | Numerical | [0, ∞] | [10, 14] |\n",
    "| City | City of residence | String | Categorical (Nominal) | Any city [e.g., \"Mumbai\", \"Bangalore\"] | 317 unique cities |\n",
    "| State | State of residence | String | Categorical (Nominal) | Any state [e.g., \"Maharashtra\", \"Tamil_Nadu\"] | 29 unique states |\n",
    "\n",
    "The dataset consists of three CSV files:\n",
    "1. `Training Data.csv`: Contains all the features along with the target variable (`Risk Flag`) and an `ID` column. \n",
    "2. `Test Data.csv`: Contains only the features and an `ID` column from the test data.\n",
    "3. `Sample Prediction Dataset.csv`: Contains the target variable (`Risk Flag`) and an `ID` column from the test data.\n",
    "\n",
    "Example Training Data:\n",
    "\n",
    "| Risk Flag | Income    | Age | Experience | Profession         | Married | House Ownership | Car Ownership | Current Job Years | Current House Years | City      | State         |\n",
    "| :-------- | :-------- | :-- | :--------- | :----------------- | :------ | :-------------- | :------------ | :---------------- | :------------------ | :-------- | :------------ |\n",
    "| 0         | 1,303,834 | 23  | 3          | Mechanical_engineer | single  | rented          | no            | 3                 | 13                   | Rewa      | Madhya_Pradesh |\n",
    "| 1         | 6,256,451 | 41  | 2          | Software_Developer | single  | rented          | yes           | 2                 | 12                   | Bangalore | Tamil_Nadu    |\n",
    "| 0         | 3,991,815 | 66  | 4          | Technical_writer   | married | rented          | no            | 4                 | 10                   | Alappuzha | Kerala        |\n",
    "\n",
    "**Technical Requirements**  \n",
    "The project must meet the following technical requirements:\n",
    "- Data Preprocessing:\n",
    "  - Load, clean, transform, and save data using `pandas` and `sklearn`.\n",
    "  - Handle duplicates, incorrect data types, missing values, and outliers.\n",
    "  - Extract features, scale numerical features, and encode categorical features.\n",
    "- Exploratory Data Analysis (EDA):\n",
    "  - Analyze descriptive statistics using `pandas` and `numpy`.\n",
    "  - Visualize distributions, correlations, and relationships using `seaborn` and `matplotlib`.\n",
    "- Modeling:\n",
    "  - Train baseline models and perform hyperparameter tuning for binary classification task with `sklearn` and `xgboost`.\n",
    "  - Baseline models: Logistic Regression, K-Nearest Neighbors, Support Vector Machine, Random Forest, Multi-Layer Perceptron, XGBoost.\n",
    "  - Evaluate model performance using Area Under the Precision-Recall Curve (AUC-PR).\n",
    "    - AUC-PR is more suitable to address class imbalance (12.3% defaults) with a focus on the positive class (preventing defaults) than accuracy, precision, recall, F1-score, and AUC-ROC.\n",
    "    - Success criterion: Minimum AUC-PR of 0.70 on the test data.\n",
    "  - Potentially use additional techniques to address class imbalance (e.g., SMOTE, class weights).\n",
    "  - Visualize feature importance, show model prediction examples, and save the final model with `pickle`.\n",
    "- Deployment:\n",
    "  - Create a REST API for model deployment and integration with existing loan processing systems.\n",
    "  - Implement efficient batch processing capabilities for multiple loan applications.\n",
    "  - Deploy using cloud infrastructure to ensure scalability and security.\n",
    "  - Develop monitoring systems for model performance and data drift.\n",
    "- Stakeholders:\n",
    "  - Loan officers: Direct users of the model predictions in day-to-day loan approvals.\n",
    "  - Credit risk analysts: Provide subject matter expertise on loan default risk.\n",
    "  - Compliance officers: Ensure the model complies with any legal and regulatory guidelines.\n",
    "  - IT department: Manage the IT infrastructure and ensure data access for the model's development and deployment. \n",
    "\n",
    "By fulfilling these objectives and requirements, the project will provide a valuable tool for predicting loan defaults, thereby enhancing decision-making for financial institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d9b38-149a-4c08-bb6a-c1ad97d33d28",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd00e3c4-73f9-45bb-a474-58fc6049796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7316e-f065-4b92-8f2c-5cd5681b5a69",
   "metadata": {},
   "source": [
    "# Data Loading\n",
    "Load data from the three .csv files into three Pandas DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f1e0114-5f1a-44ce-85e7-3136fe031aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(\"data/training_data.csv\")\n",
    "    X_test = pd.read_csv(\"data/test_data.csv\")\n",
    "    y_test = pd.read_csv(\"data/sample_prediction_dataset.csv\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: The file content could not be parsed as a CSV.\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied when accessing the file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866b8d1-12e6-4f47-b54e-8132b55b4c1e",
   "metadata": {},
   "source": [
    "# Initial Data Inspection  \n",
    "Basic exploration of the dataset to understand its structure and detect obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1bc38bee-eefa-48ce-9ddb-b9464e6caa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252000 entries, 0 to 251999\n",
      "Data columns (total 13 columns):\n",
      " #   Column             Non-Null Count   Dtype \n",
      "---  ------             --------------   ----- \n",
      " 0   Id                 252000 non-null  int64 \n",
      " 1   Income             252000 non-null  int64 \n",
      " 2   Age                252000 non-null  int64 \n",
      " 3   Experience         252000 non-null  int64 \n",
      " 4   Married/Single     252000 non-null  object\n",
      " 5   House_Ownership    252000 non-null  object\n",
      " 6   Car_Ownership      252000 non-null  object\n",
      " 7   Profession         252000 non-null  object\n",
      " 8   CITY               252000 non-null  object\n",
      " 9   STATE              252000 non-null  object\n",
      " 10  CURRENT_JOB_YRS    252000 non-null  int64 \n",
      " 11  CURRENT_HOUSE_YRS  252000 non-null  int64 \n",
      " 12  Risk_Flag          252000 non-null  int64 \n",
      "dtypes: int64(7), object(6)\n",
      "memory usage: 25.0+ MB\n",
      "None\n",
      "\n",
      "Test Data - Features:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   ID                 28000 non-null  int64 \n",
      " 1   Income             28000 non-null  int64 \n",
      " 2   Age                28000 non-null  int64 \n",
      " 3   Experience         28000 non-null  int64 \n",
      " 4   Married/Single     28000 non-null  object\n",
      " 5   House_Ownership    28000 non-null  object\n",
      " 6   Car_Ownership      28000 non-null  object\n",
      " 7   Profession         28000 non-null  object\n",
      " 8   CITY               28000 non-null  object\n",
      " 9   STATE              28000 non-null  object\n",
      " 10  CURRENT_JOB_YRS    28000 non-null  int64 \n",
      " 11  CURRENT_HOUSE_YRS  28000 non-null  int64 \n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 2.6+ MB\n",
      "None\n",
      "\n",
      "Test Data - Target Variable:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28000 entries, 0 to 27999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype\n",
      "---  ------     --------------  -----\n",
      " 0   id         28000 non-null  int64\n",
      " 1   risk_flag  28000 non-null  int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 437.6 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show DataFrame info to check the number of rows and columns, data types and missing values\n",
    "print(\"Training Data:\")\n",
    "print(df_train.info())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.info())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ea3692-d2c8-46f1-b0ad-36372c1fa4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Married/Single</th>\n",
       "      <th>House_Ownership</th>\n",
       "      <th>Car_Ownership</th>\n",
       "      <th>Profession</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CURRENT_JOB_YRS</th>\n",
       "      <th>CURRENT_HOUSE_YRS</th>\n",
       "      <th>Risk_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1303834</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Mechanical_engineer</td>\n",
       "      <td>Rewa</td>\n",
       "      <td>Madhya_Pradesh</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7574516</td>\n",
       "      <td>40</td>\n",
       "      <td>10</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Parbhani</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3991815</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Technical_writer</td>\n",
       "      <td>Alappuzha</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6256451</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Software_Developer</td>\n",
       "      <td>Bhubaneswar</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5768871</td>\n",
       "      <td>47</td>\n",
       "      <td>11</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Civil_servant</td>\n",
       "      <td>Tiruchirappalli[10]</td>\n",
       "      <td>Tamil_Nadu</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Income  Age  Experience Married/Single House_Ownership Car_Ownership  \\\n",
       "0   1  1303834   23           3         single          rented            no   \n",
       "1   2  7574516   40          10         single          rented            no   \n",
       "2   3  3991815   66           4        married          rented            no   \n",
       "3   4  6256451   41           2         single          rented           yes   \n",
       "4   5  5768871   47          11         single          rented            no   \n",
       "\n",
       "            Profession                 CITY           STATE  CURRENT_JOB_YRS  \\\n",
       "0  Mechanical_engineer                 Rewa  Madhya_Pradesh                3   \n",
       "1   Software_Developer             Parbhani     Maharashtra                9   \n",
       "2     Technical_writer            Alappuzha          Kerala                4   \n",
       "3   Software_Developer          Bhubaneswar          Odisha                2   \n",
       "4        Civil_servant  Tiruchirappalli[10]      Tamil_Nadu                3   \n",
       "\n",
       "   CURRENT_HOUSE_YRS  Risk_Flag  \n",
       "0                 13          0  \n",
       "1                 13          0  \n",
       "2                 10          0  \n",
       "3                 12          1  \n",
       "4                 14          1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top five rows of the training data\n",
    "print(\"Training Data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9890b354-634e-46b6-aaf0-0868ad775bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data - Features:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Income</th>\n",
       "      <th>Age</th>\n",
       "      <th>Experience</th>\n",
       "      <th>Married/Single</th>\n",
       "      <th>House_Ownership</th>\n",
       "      <th>Car_Ownership</th>\n",
       "      <th>Profession</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>CURRENT_JOB_YRS</th>\n",
       "      <th>CURRENT_HOUSE_YRS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7393090</td>\n",
       "      <td>59</td>\n",
       "      <td>19</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Geologist</td>\n",
       "      <td>Malda</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1215004</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Firefighter</td>\n",
       "      <td>Jalna</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8901342</td>\n",
       "      <td>50</td>\n",
       "      <td>12</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>no</td>\n",
       "      <td>Lawyer</td>\n",
       "      <td>Thane</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1944421</td>\n",
       "      <td>49</td>\n",
       "      <td>9</td>\n",
       "      <td>married</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Analyst</td>\n",
       "      <td>Latur</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13429</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>single</td>\n",
       "      <td>rented</td>\n",
       "      <td>yes</td>\n",
       "      <td>Comedian</td>\n",
       "      <td>Berhampore</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID   Income  Age  Experience Married/Single House_Ownership Car_Ownership  \\\n",
       "0   1  7393090   59          19         single          rented            no   \n",
       "1   2  1215004   25           5         single          rented            no   \n",
       "2   3  8901342   50          12         single          rented            no   \n",
       "3   4  1944421   49           9        married          rented           yes   \n",
       "4   5    13429   25          18         single          rented           yes   \n",
       "\n",
       "    Profession        CITY        STATE  CURRENT_JOB_YRS  CURRENT_HOUSE_YRS  \n",
       "0    Geologist       Malda  West Bengal                4                 13  \n",
       "1  Firefighter       Jalna  Maharashtra                5                 10  \n",
       "2       Lawyer       Thane  Maharashtra                9                 14  \n",
       "3      Analyst       Latur  Maharashtra                3                 12  \n",
       "4     Comedian  Berhampore  West Bengal               13                 11  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top five rows of the test data features\n",
    "print(\"Test Data - Features:\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ad411a4-8229-41b9-843b-ba280a6b6599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Data - Target Variable:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>risk_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  risk_flag\n",
       "0   1          0\n",
       "1   2          0\n",
       "2   3          1\n",
       "3   4          0\n",
       "4   5          0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show top five rows of the test data target variable\n",
    "print(\"Test Data - Target Variable:\")\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9596-7328-43a4-8cf6-a18d1b64b4f7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af4f32-03ee-43b6-9289-6821b800328b",
   "metadata": {},
   "source": [
    "## Handling Inconsistent Column Names\n",
    "Problem: Some column names are inconsistent across the training and test dataset (e.g., \"Id\" vs. \"ID\", \"Risk_Flag\" vs. \"risk_flag\").  \n",
    "Solution: Consistently use snake_case for all column names in the training and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68e438b-50b7-4391-8b8e-0b54f1d8b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names to lowercase and replace \"/\" with \"_\"\n",
    "df_train.columns = df_train.columns.str.lower().str.replace(\"/single\", \"\")\n",
    "X_test.columns = X_test.columns.str.lower().str.replace(\"/single\", \"\")\n",
    "y_test.columns = y_test.columns.str.lower().str.replace(\"/single\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07565d7a-e2b0-472d-91dd-f860878e384b",
   "metadata": {},
   "source": [
    "## Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30d98e50-9696-47fe-b1ad-51ec59375e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "False    252000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Features:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Target Variable:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicates based on all columns\n",
    "print(\"Training Data:\")\n",
    "print(df_train.duplicated().value_counts())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.duplicated().value_counts())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b48ba-dc42-4591-bc44-e490092a79f2",
   "metadata": {},
   "source": [
    "No duplicates were found based on all columns in both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8469e53c-dcfa-42eb-8542-7f215b4d3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "False    252000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Features:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Target Variable:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Identify duplicates based on the ID column\n",
    "print(\"Training Data:\")\n",
    "print(df_train.duplicated(subset=[\"id\"]).value_counts())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.duplicated(subset=[\"id\"]).value_counts())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.duplicated(subset=[\"id\"]).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57954bf9-09ec-49df-8cb7-ed39d546d14f",
   "metadata": {},
   "source": [
    "No duplicates were found based on the ID column in both the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89142d-7b4a-4b23-98b3-3c9e63ee5eb8",
   "metadata": {},
   "source": [
    "## Handling Incorrect Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3be913b0-2788-4e8d-8797-37233709dfa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "id                    int64\n",
      "income                int64\n",
      "age                   int64\n",
      "experience            int64\n",
      "married              object\n",
      "house_ownership      object\n",
      "car_ownership        object\n",
      "profession           object\n",
      "city                 object\n",
      "state                object\n",
      "current_job_yrs       int64\n",
      "current_house_yrs     int64\n",
      "risk_flag             int64\n",
      "dtype: object\n",
      "\n",
      "Test Data - Features:\n",
      "id                    int64\n",
      "income                int64\n",
      "age                   int64\n",
      "experience            int64\n",
      "married              object\n",
      "house_ownership      object\n",
      "car_ownership        object\n",
      "profession           object\n",
      "city                 object\n",
      "state                object\n",
      "current_job_yrs       int64\n",
      "current_house_yrs     int64\n",
      "dtype: object\n",
      "\n",
      "Test Data - Target Variable:\n",
      "id           int64\n",
      "risk_flag    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Identify incorrect data types\n",
    "print(\"Training Data:\")\n",
    "print(df_train.dtypes)\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.dtypes)\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45da11a2-50d5-4c7a-907e-3b71830f0295",
   "metadata": {},
   "source": [
    "No incorrect data types were found at first glance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "39d0d39d-104b-47b4-8538-ffd2f55a0e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "married              2\n",
      "house_ownership      3\n",
      "car_ownership        2\n",
      "profession          51\n",
      "city               317\n",
      "state               29\n",
      "dtype: int64\n",
      "\n",
      "Test Data - Features:\n",
      "married              2\n",
      "house_ownership      3\n",
      "car_ownership        2\n",
      "profession          51\n",
      "city               317\n",
      "state               29\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Explore number of unique categories in object columns\n",
    "print(\"Training Data:\")\n",
    "print(df_train[df_train.select_dtypes(include=[\"object\"]).columns.tolist()].nunique())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test[X_test.select_dtypes(include=[\"object\"]).columns.tolist()].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c09ab91-0a64-4def-9314-e7537e7e1d41",
   "metadata": {},
   "source": [
    "Convert object columns with two unique categories to boolean columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876603a-e2d3-493e-a1a7-cdf2233a8551",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert married and car_ownership column from object to boolean\n",
    "df_train[\"married\"] = df_train[\"married\"].map({\"married\": True, \"single\": False})\n",
    "X_test[\"married\"] = X_test[\"married\"].map({\"married\": True, \"single\": False})\n",
    "df_train[\"car_ownership\"] = df_train[\"car_ownership\"].map({\"yes\": True, \"no\": False})\n",
    "X_test[\"car_ownership\"] = X_test[\"car_ownership\"].map({\"yes\": True, \"no\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f13d765-a4ad-40b3-8913-3914c749ab2e",
   "metadata": {},
   "source": [
    "## Defining Column Types  \n",
    "Define numerical, categorical and boolean columns for downstream tasks like additional preprocessing steps, exploratory data analysis, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d07e51-218e-4826-99cc-73de5abf3df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column types manually\n",
    "numerical_columns = [\"income\", \"age\", \"experience\", \"current_job_yrs\", \"current_house_yrs\"]\n",
    "categorical_columns = [\"house_ownership\", \"profession\", \"city\", \"state\"]\n",
    "boolean_columns = [\"married\", \"car_ownership\", \"risk_flag\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413ec8b-66cd-4d93-a071-7b076db6fbf4",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef07a4d2-f28d-4ad1-a618-fde9e0753d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore number of unique categories in categorical columns\n",
    "print(\"Training Data:\")\n",
    "print(df_train[categorical_columns].nunique())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test[categorical_columns].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332edd65-5789-48e4-8aa6-d055d94711b5",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f37db6-2329-44af-90ab-ec03a0e6bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify missing values\n",
    "print(\"Training Data:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.isnull().sum())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e30f60-8cfa-419d-a915-e37a9ddde4ac",
   "metadata": {},
   "source": [
    "No missing values were found in any of the columns in both the training and test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f386d0a-d26f-462c-96f4-4b557da2943c",
   "metadata": {},
   "source": [
    "## Handling Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f7375e-b714-44f3-b184-c28af316e22a",
   "metadata": {},
   "source": [
    "### 3SD Method  \n",
    "Identify and remove univariate outliers in numerical columns by applying the 3 standard deviation (SD) rule. Specifically, a data point is considered an outlier if it falls more than 3 standard deviations above or below the mean of the column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b38504-167d-42e9-9bd5-ab44c552929d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom transformer class to identify and remove outliers using the 3SD method\n",
    "class OutlierRemover3SD(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df, numerical_columns):\n",
    "        # Convert single column string to list\n",
    "        if isinstance(numerical_columns, str):\n",
    "            numerical_columns = [numerical_columns]\n",
    "            \n",
    "        # Calculate statistics (mean, standard deviation, cutoff values) for each column\n",
    "        self.stats_ = pd.DataFrame(index=numerical_columns)\n",
    "        self.stats_[\"mean\"] = df[numerical_columns].mean()\n",
    "        self.stats_[\"sd\"] = df[numerical_columns].std()\n",
    "        self.stats_[\"lower_cutoff\"] = self.stats_[\"mean\"] - 3 * self.stats_[\"sd\"]\n",
    "        self.stats_[\"upper_cutoff\"] = self.stats_[\"mean\"] + 3 * self.stats_[\"sd\"]\n",
    "\n",
    "        # Create masks for filtering outliers \n",
    "        self.masks_ = (df[numerical_columns] >= self.stats_[\"lower_cutoff\"]) & (df[numerical_columns] <= self.stats_[\"upper_cutoff\"])  # masks by column\n",
    "        self.final_mask_ = self.masks_.all(axis=1)  # single mask across all columns\n",
    "\n",
    "        # Calculate number of outliers\n",
    "        self.stats_[\"outliers\"] = (~self.masks_).sum()  # by column\n",
    "        self.outliers_ = (~self.final_mask_).sum()  # across all columns\n",
    "        \n",
    "        # Show statistics and number of outliers\n",
    "        print(f\"Statistics and outliers: \\n{self.stats_}\")\n",
    "        if len(numerical_columns) == 1:\n",
    "            print(f\"\\n{self.outliers_} rows contain outliers in the '{numerical_columns[0]}' column.\")\n",
    "        else:\n",
    "            print(f\"\\n{self.outliers_} rows contain outliers in one or more numerical columns.\")\n",
    "  \n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        # Remove outliers based on the final mask\n",
    "        print(f\"{self.outliers_} rows with outliers removed.\")\n",
    "        return df[self.final_mask_]\n",
    "\n",
    "    def fit_transform(self, df, numerical_columns):\n",
    "        # Perform both fit and transform \n",
    "        return self.fit(df, numerical_columns).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7efcbf-bec0-49f6-82bc-ec0d98ca51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize outlier remover \n",
    "outlier_remover_3sd = OutlierRemover3SD()\n",
    "\n",
    "# Identify and remove outliers\n",
    "df_train = outlier_remover_3sd.fit_transform(df_train, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858552d1-4764-4364-8440-30409e324a57",
   "metadata": {},
   "source": [
    "### 1.5 IQR Method  \n",
    "Identify and remove univariate outliers in numerical columns using the 1.5 interquartile range (IQR) rule. Specifically, a data point is considered an outlier if it falls more than 1.5 interquartile ranges above the third quartile (Q3) or below the first quartile (Q1) of the column.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f7b0d-c5dd-4820-974e-445571f160da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom transformer class to identify and remove outliers using the 1.5 IQR method\n",
    "class OutlierRemoverIQR(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, df, numerical_columns):\n",
    "        # Convert single column string to list\n",
    "        if isinstance(numerical_columns, str):\n",
    "            numerical_columns = [numerical_columns]\n",
    "        \n",
    "        # Calculate statistics (first quartile, third quartile, interquartile range, cutoff values) for each column\n",
    "        self.stats_ = pd.DataFrame(index=numerical_columns)\n",
    "        self.stats_[\"Q1\"] = df[numerical_columns].quantile(0.25)\n",
    "        self.stats_[\"Q3\"] = df[numerical_columns].quantile(0.75)\n",
    "        self.stats_[\"IQR\"] = self.stats_[\"Q3\"] - self.stats_[\"Q1\"]\n",
    "        self.stats_[\"lower_cutoff\"] = self.stats_[\"Q1\"] - 1.5 * self.stats_[\"IQR\"]\n",
    "        self.stats_[\"upper_cutoff\"] = self.stats_[\"Q3\"] + 1.5 * self.stats_[\"IQR\"]\n",
    "\n",
    "        # Create masks for filtering outliers \n",
    "        self.masks_ = (df[numerical_columns] >= self.stats_[\"lower_cutoff\"]) & (df[numerical_columns] <= self.stats_[\"upper_cutoff\"])  # masks by column\n",
    "        self.final_mask_ = self.masks_.all(axis=1)  # single mask across all columns\n",
    "\n",
    "        # Calculate number of outliers\n",
    "        self.stats_[\"outliers\"] = (~self.masks_).sum()  # by column\n",
    "        self.outliers_ = (~self.final_mask_).sum()  # across all columns\n",
    "               \n",
    "        # Show statistics and number of outliers\n",
    "        print(f\"Statistics and outliers: \\n{self.stats_}\")\n",
    "        if len(numerical_columns) == 1:\n",
    "            print(f\"\\n{self.outliers_} rows contain outliers in the '{numerical_columns[0]}' column.\")\n",
    "        else:\n",
    "            print(f\"\\n{self.outliers_} rows contain outliers in one or more numerical columns.\")\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, df):\n",
    "        # Remove outliers based on the final mask\n",
    "        print(f\"{self.outliers_} rows with outliers removed.\")\n",
    "        return df[self.final_mask_]\n",
    "\n",
    "    def fit_transform(self, df, numerical_columns):\n",
    "        # Perform both fit and transform\n",
    "        return self.fit(df, numerical_columns).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c6dc1b-0947-4db4-98d7-77371aa6bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize outlier remover \n",
    "outlier_remover_iqr = OutlierRemoverIQR()\n",
    "\n",
    "# Identify and remove outliers\n",
    "df_train = outlier_remover_iqr.fit_transform(df_train, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6815f4f-0f4f-456f-8eb3-6eaebf035b19",
   "metadata": {},
   "source": [
    "# Future Improvements\n",
    "\n",
    "**Data Enrichment**:  \n",
    "To enhance the model's performance and business value, data enrichment with the following financial features is recommended:\n",
    "- Loan amount \n",
    "- Loan duration\n",
    "- Interest rate\n",
    "- Type of loan (e.g., personal, home, vehicle)\n",
    "- Existing debt\n",
    "- Credit score\n",
    "\n",
    "**Enhanced Analysis Capabilities**:  \n",
    "The addition of these features, particularly loan amount, would enable more precise risk assessment and better alignment with business objectives through cost-sensitive evaluation metrics incorporating actual monetary values. Cost-sensitive metrics or expected monetary value incorporate the actual cost of defaults (false negatives) and the opportunity cost of rejecting good loans (false positives)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-default-venv",
   "language": "python",
   "name": "loan-default-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
