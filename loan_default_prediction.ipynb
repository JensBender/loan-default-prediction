{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4275851-2816-4903-91c3-8b4a4c489b12",
   "metadata": {},
   "source": [
    "# Project Overview: Predicting Loan Defaults\n",
    "\n",
    "**Executive Summary**  \n",
    "This project aims to develop a machine learning model to predict whether the customers of a financial institution will default on a loan based on data from their loan application. Accurately identifying potential defaulters enables financial institutions to make informed lending decisions, adjust loan terms, and better manage financial risk.\n",
    "\n",
    "**Problem**  \n",
    "Predicting loan defaults is a challenging task due to the multitude of influencing factors such as customer demographics (e.g., age, income, profession) and financial background information (e.g., house ownership, years in the job, car ownership). Traditional default prediction models often oversimplify complex relationships between customer features and default risk. Machine learning offers enhanced predictive capability by capturing non-linear patterns and intricate dependencies in loan application data, enabling more accurate predictions of loan default risk.\n",
    "\n",
    "**Objectives**  \n",
    "The project aims to:\n",
    "- Develop a machine learning model to predict loan defaults using customer data from loan applications.\n",
    "- Compare multiple models (e.g., Logistic Regression, Random Forest, XGBoost) using the Area Under the Precision-Recall Curve (AUC-PR), an evaluation metric suited for class imbalance.\n",
    "- Identify key factors influencing loan default risk through feature importance analysis.\n",
    "\n",
    "**Value Proposition**  \n",
    "This project enables financial institutions to reduce loan default rates and make faster lending decisions through improved and automated risk assessment using machine learning. \n",
    "\n",
    "**Business Goals**  \n",
    "The project aims to achieve the following business goals:\n",
    "- Reduce losses by 100,000-200,000$ within 12 months after model deployment by decreasing the loan default rate by 10%-20%.\n",
    "- Decrease loan processing time by 25%-40% by automating risk assessment, leading to less time spent on manual evaluations.\n",
    "- Achieve 100% regulatory compliance with fair lending practices.\n",
    "\n",
    "**Data**  \n",
    "The dataset contains information provided by customers of a financial institution during the loan application process. It is sourced from the \"Loan Prediction Based on Customer Behavior\" dataset by Subham Jain, available on [Kaggle](https://www.kaggle.com/datasets/subhamjain/loan-prediction-based-on-customer-behavior). \n",
    "\n",
    "Dataset Statistics:\n",
    "- Training set size: 252,000 records (12.3% defaults)\n",
    "- Test set size: 28,000 records (12.8% defaults)\n",
    "- Features: 11 demographic, financial, job, and location attributes of loan applicants\n",
    "\n",
    "Data Overview Table:\n",
    "\n",
    "| Column | Description | Storage Type | Semantic Type | Theoretical Range | Training Data Range |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| Risk Flag | Defaulted on loan (0: No, 1: Yes) | Integer | Categorical (Binary) | [0, 1] | [0, 1] |\n",
    "| Income | Income of the applicant | Integer | Numerical | [0, ∞] | [10K, 10M] |\n",
    "| Age | Age of the applicant (in years) | Integer | Numerical | [18, ∞] | [21, 79] |\n",
    "| Experience | Work experience (in years) | Integer | Numerical | [0, ∞] | [0, 20] |\n",
    "| Profession | Applicant's profession | String | Categorical (Nominal) | Any profession [e.g., \"Architect\", \"Dentist\"] | 8 unique professions |\n",
    "| Married | Marital status | String | Categorical (Binary) | [\"single\", \"married\"] | [\"single\", \"married\"] |\n",
    "| House Ownership | Applicant owns or rents a house | String | Categorical (Nominal) | [\"rented\", \"owned\", \"norent_noown\"] | [\"rented\", \"owned\", \"norent_noown\"] |\n",
    "| Car Ownership | Whether applicant owns a car | String | Categorical (Binary) | [\"yes\", \"no\"] | [\"yes\", \"no\"] |\n",
    "| Current Job Years | Years in the current job | Integer | Numerical | [0, ∞] | [0, 14] |\n",
    "| Current House Years | Years in the current house | Integer | Numerical | [0, ∞] | [10, 14] |\n",
    "| City | City of residence | String | Categorical (Nominal) | Any city [e.g., \"Mumbai\", \"Bangalore\"] | 317 unique cities |\n",
    "| State | State of residence | String | Categorical (Nominal) | Any state [e.g., \"Maharashtra\", \"Tamil_Nadu\"] | 5 unique states |\n",
    "\n",
    "The dataset consists of three CSV files:\n",
    "1. `Training Data.csv`: Contains all the features along with the target variable (`Risk Flag`) and an `ID` column. \n",
    "2. `Test Data.csv`: Contains only the features and an `ID` column from the test data.\n",
    "3. `Sample Prediction Dataset.csv`: Contains the target variable (`Risk Flag`) and an `ID` column from the test data.\n",
    "\n",
    "Example Training Data:\n",
    "\n",
    "| Risk Flag | Income    | Age | Experience | Profession         | Married | House Ownership | Car Ownership | Current Job Years | Current House Years | City      | State         |\n",
    "| :-------- | :-------- | :-- | :--------- | :----------------- | :------ | :-------------- | :------------ | :---------------- | :------------------ | :-------- | :------------ |\n",
    "| 0         | 1,303,834 | 23  | 3          | Mechanical_engineer | single  | rented          | no            | 3                 | 13                   | Rewa      | Madhya_Pradesh |\n",
    "| 1         | 6,256,451 | 41  | 2          | Software_Developer | single  | rented          | yes           | 2                 | 12                   | Bangalore | Tamil_Nadu    |\n",
    "| 0         | 3,991,815 | 66  | 4          | Technical_writer   | married | rented          | no            | 4                 | 10                   | Alappuzha | Kerala        |\n",
    "\n",
    "**Technical Requirements**  \n",
    "The project must meet the following technical requirements:\n",
    "- Data Preprocessing:\n",
    "  - Load, clean, transform, and save data using `pandas` and `sklearn`.\n",
    "  - Handle duplicates, incorrect data types, missing values, and outliers.\n",
    "  - Extract features, scale numerical features, and encode categorical features.\n",
    "- Exploratory Data Analysis (EDA):\n",
    "  - Analyze descriptive statistics using `pandas` and `numpy`.\n",
    "  - Visualize distributions, correlations, and relationships using `seaborn` and `matplotlib`.\n",
    "- Modeling:\n",
    "  - Train baseline models and perform hyperparameter tuning for binary classification task with `sklearn` and `xgboost`.\n",
    "  - Baseline models: Logistic Regression, K-Nearest Neighbors, Support Vector Machine, Random Forest, Multi-Layer Perceptron, XGBoost.\n",
    "  - Evaluate model performance using Area Under the Precision-Recall Curve (AUC-PR).\n",
    "    - AUC-PR is more suitable to address class imbalance (12.3% defaults) with a focus on the positive class (preventing defaults) than accuracy, precision, recall, F1-score, and AUC-ROC.\n",
    "    - Success criterion: Minimum AUC-PR of 0.70 on the test data.\n",
    "  - Potentially use additional techniques to address class imbalance (e.g., SMOTE, class weights).\n",
    "  - Visualize feature importance, show model prediction examples, and save the final model with `pickle`.\n",
    "- Deployment:\n",
    "  - Create a REST API for model deployment and integration with existing loan processing systems.\n",
    "  - Implement efficient batch processing capabilities for multiple loan applications.\n",
    "  - Deploy using cloud infrastructure to ensure scalability and security.\n",
    "  - Develop monitoring systems for model performance and data drift.\n",
    "- Stakeholders:\n",
    "  - Loan officers: Direct users of the predictions in day-to-day loan approvals.\n",
    "  - Credit risk analysts: Provide subject matter expertise on loan data defaults.\n",
    "  - Compliance officers: Ensure the model adheres to any legal or regulatory guidelines.\n",
    "  - IT department: Ensure infrastructure and data access for the model's development and deployment. \n",
    "\n",
    "By fulfilling these objectives and requirements, the project will provide a valuable tool for predicting loan defaults, thereby enhancing decision-making for financial institutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6d9b38-149a-4c08-bb6a-c1ad97d33d28",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd00e3c4-73f9-45bb-a474-58fc6049796e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e7316e-f065-4b92-8f2c-5cd5681b5a69",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70baf18b-5437-4c7d-b74f-d432ee23be5c",
   "metadata": {},
   "source": [
    "## CSV \n",
    "Load data from a .csv file into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1e0114-5f1a-44ce-85e7-3136fe031aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_train = pd.read_csv(\"data/training_data.csv\")\n",
    "    X_test = pd.read_csv(\"data/test_data.csv\")\n",
    "    y_test = pd.read_csv(\"data/sample_prediction_dataset.csv\")\n",
    "    print(\"Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File not found. Please check the file path.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"Error: The file is empty.\")\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Error: The file content could not be parsed as a CSV.\")\n",
    "except PermissionError:\n",
    "    print(\"Error: Permission denied when accessing the file.\")\n",
    "except Exception as e:\n",
    "    print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7866b8d1-12e6-4f47-b54e-8132b55b4c1e",
   "metadata": {},
   "source": [
    "# Initial Data Inspection  \n",
    "Basic exploration of the dataset to understand its structure and detect obvious issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc38bee-eefa-48ce-9ddb-b9464e6caa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show DataFrame info to check the number of rows and columns, data types and missing values\n",
    "print(\"Training Data:\")\n",
    "print(df_train.info())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.info())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea3692-d2c8-46f1-b0ad-36372c1fa4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top five rows of the training data\n",
    "print(\"Training Data:\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890b354-634e-46b6-aaf0-0868ad775bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top five rows of the test data features\n",
    "print(\"Test Data - Features:\")\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad411a4-8229-41b9-843b-ba280a6b6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top five rows of the test data target variable\n",
    "print(\"Test Data - Target Variable:\")\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fceb9596-7328-43a4-8cf6-a18d1b64b4f7",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07af4f32-03ee-43b6-9289-6821b800328b",
   "metadata": {},
   "source": [
    "## Handling Inconsistent Column Names\n",
    "Some column names are inconsistent across the training and test dataset (e.g., \"Id\" vs. \"ID\", \"Risk_Flag\" vs. \"risk_flag\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e438b-50b7-4391-8b8e-0b54f1d8b9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change column names to lowercase and replace \"/\" with \"_\"\n",
    "df_train.columns = df_train.columns.str.lower().str.replace(\"/\", \"_\")\n",
    "X_test.columns = X_test.columns.str.lower().str.replace(\"/\", \"_\")\n",
    "y_test.columns = y_test.columns.str.lower().str.replace(\"/\", \"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07565d7a-e2b0-472d-91dd-f860878e384b",
   "metadata": {},
   "source": [
    "## Handling Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1bd8b-5c42-4236-a481-eba15643a694",
   "metadata": {},
   "source": [
    "Duplicates based on all columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "30d98e50-9696-47fe-b1ad-51ec59375e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "False    252000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Features:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Target Variable:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Diagnose duplicates based on all columns\n",
    "print(\"Training Data:\")\n",
    "print(df_train.duplicated().value_counts())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.duplicated().value_counts())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.duplicated().value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0b48ba-dc42-4591-bc44-e490092a79f2",
   "metadata": {},
   "source": [
    "No duplicates based on all columns in training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8517791c-e872-4d32-96cf-5974efc0526d",
   "metadata": {},
   "source": [
    "Duplicates based on the ID column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8469e53c-dcfa-42eb-8542-7f215b4d3e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "False    252000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Features:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Test Data - Target Variable:\n",
      "False    28000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Diagnose duplicates based on ID column\n",
    "print(\"Training Data:\")\n",
    "print(df_train.duplicated(subset=[\"id\"]).value_counts())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.duplicated(subset=[\"id\"]).value_counts())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.duplicated(subset=[\"id\"]).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57954bf9-09ec-49df-8cb7-ed39d546d14f",
   "metadata": {},
   "source": [
    "There are no duplicates based on the ID column in the training data, the test data features, or the test data target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec89142d-7b4a-4b23-98b3-3c9e63ee5eb8",
   "metadata": {},
   "source": [
    "## Handling Incorrect Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3be913b0-2788-4e8d-8797-37233709dfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "id                    int64\n",
      "income                int64\n",
      "age                   int64\n",
      "experience            int64\n",
      "married_single       object\n",
      "house_ownership      object\n",
      "car_ownership        object\n",
      "profession           object\n",
      "city                 object\n",
      "state                object\n",
      "current_job_yrs       int64\n",
      "current_house_yrs     int64\n",
      "risk_flag             int64\n",
      "dtype: object\n",
      "\n",
      "Test Data - Features:\n",
      "id                    int64\n",
      "income                int64\n",
      "age                   int64\n",
      "experience            int64\n",
      "married_single       object\n",
      "house_ownership      object\n",
      "car_ownership        object\n",
      "profession           object\n",
      "city                 object\n",
      "state                object\n",
      "current_job_yrs       int64\n",
      "current_house_yrs     int64\n",
      "dtype: object\n",
      "\n",
      "Test Data - Target Variable:\n",
      "id           int64\n",
      "risk_flag    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Diagnose incorrect data types\n",
    "print(\"Training Data:\")\n",
    "print(df_train.dtypes)\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.dtypes)\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be64e9b1-5b3b-459c-8b1c-456c683691c2",
   "metadata": {},
   "source": [
    "All the columns in the training and test data have the correct data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413ec8b-66cd-4d93-a071-7b076db6fbf4",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ef07a4d2-f28d-4ad1-a618-fde9e0753d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "married_single       2\n",
       "house_ownership      3\n",
       "car_ownership        2\n",
       "profession          51\n",
       "city               317\n",
       "state               29\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore number of unique categories in string columns\n",
    "categorical_columns = df_train.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "df_train[categorical_columns].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332edd65-5789-48e4-8aa6-d055d94711b5",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f37db6-2329-44af-90ab-ec03a0e6bd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose missing values\n",
    "print(\"Training Data:\")\n",
    "print(df_train.isnull().sum())\n",
    "print(\"\\nTest Data - Features:\")\n",
    "print(X_test.isnull().sum())\n",
    "print(\"\\nTest Data - Target Variable:\")\n",
    "print(y_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e30f60-8cfa-419d-a915-e37a9ddde4ac",
   "metadata": {},
   "source": [
    "There are no missing values in the training data, the test data features, or the test data target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6815f4f-0f4f-456f-8eb3-6eaebf035b19",
   "metadata": {},
   "source": [
    "# Future Improvements\n",
    "\n",
    "**Data Enrichment**:  \n",
    "To enhance the model's performance and business value, data enrichment with the following financial features is recommended:\n",
    "- Loan amount \n",
    "- Loan duration\n",
    "- Interest rate\n",
    "- Type of loan (e.g., personal, home, vehicle)\n",
    "- Existing debt\n",
    "- Credit score\n",
    "\n",
    "**Enhanced Analysis Capabilities**:  \n",
    "The addition of these features, particularly loan amount, would enable more precise risk assessment and better alignment with business objectives through cost-sensitive evaluation metrics incorporating actual monetary values. Cost-sensitive metrics or expected monetary value incorporate the actual cost of defaults (false negatives) and the opportunity cost of rejecting good loans (false positives)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "loan-default-venv",
   "language": "python",
   "name": "loan-default-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
